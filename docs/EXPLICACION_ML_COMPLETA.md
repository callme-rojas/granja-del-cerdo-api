# ü§ñ EXPLICACI√ìN COMPLETA DEL SISTEMA DE MACHINE LEARNING

## üìã √çNDICE
1. [Visi√≥n General del Flujo](#1-visi√≥n-general-del-flujo)
2. [Generaci√≥n de Datos de Entrenamiento](#2-generaci√≥n-de-datos-de-entrenamiento)
3. [Preparaci√≥n de Features](#3-preparaci√≥n-de-features)
4. [Entrenamiento del Modelo](#4-entrenamiento-del-modelo)
5. [Predicci√≥n en Tiempo Real](#5-predicci√≥n-en-tiempo-real)
6. [Componentes T√©cnicos](#6-componentes-t√©cnicos)

---

## 1. VISI√ìN GENERAL DEL FLUJO

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUJO COMPLETO DEL ML                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

FASE 1: ENTRENAMIENTO (Una vez, offline)
‚îú‚îÄ‚îÄ Generar 360 lotes sint√©ticos (12 meses)
‚îú‚îÄ‚îÄ Extraer 10 features de cada lote
‚îú‚îÄ‚îÄ Calcular precio_venta_final_kg (target)
‚îú‚îÄ‚îÄ Normalizar features con StandardScaler
‚îú‚îÄ‚îÄ Entrenar 3 modelos (Linear, RandomForest, GradientBoosting)
‚îú‚îÄ‚îÄ Evaluar con validaci√≥n cruzada (K-Fold)
‚îú‚îÄ‚îÄ Seleccionar mejor modelo (menor MAE)
‚îî‚îÄ‚îÄ Guardar modelo + scaler en .pkl

FASE 2: PREDICCI√ìN (Cada vez que se solicita)
‚îú‚îÄ‚îÄ Obtener datos del lote desde BD
‚îú‚îÄ‚îÄ Construir 10 features del lote
‚îú‚îÄ‚îÄ Normalizar features con el scaler guardado
‚îú‚îÄ‚îÄ Predecir precio con el modelo entrenado
‚îî‚îÄ‚îÄ Aplicar margen adicional si se solicita
```

---

## 2. GENERACI√ìN DE DATOS DE ENTRENAMIENTO

**Archivo:** `api/ml/data/generate_data.py` ‚Üí `generar_lote()`

### ¬øQu√© hace?
Genera 360 lotes sint√©ticos que simulan 12 meses de operaci√≥n real.

### Proceso paso a paso:

#### 2.1. Generar caracter√≠sticas b√°sicas
```python
cantidad_animales = 15-100 animales (aleatorio)
peso_promedio_entrada = 80-115 kg (distribuci√≥n normal)
precio_compra_kg = 18-25 Bs/kg (uniforme)
duracion_estadia_dias = 1-3 d√≠as (discreta)
mes_adquisicion = 1-12 (estacionalidad)
```

#### 2.2. Calcular pesos y costos
```python
kilos_entrada = cantidad_animales √ó peso_promedio_entrada

# NUEVO: Ganancia de peso realista
ganancia_por_dia = 0.8-1.5 kg/cerdo/d√≠a (aleatorio)
ganancia_total = ganancia_por_dia √ó cantidad √ó d√≠as
kilos_salida = kilos_entrada + ganancia_total

# Costos log√≠sticos (RANGOS AMPLIADOS)
costo_logistica = base (150-500 Bs) + por_animal (10-50 Bs/animal) + ruido
# Rango total: ~310 Bs (lote peque√±o) hasta ~6,500 Bs (lote grande de 100 animales)

# Costos alimentaci√≥n (solo si estad√≠a > 1 d√≠a) - RANGOS AMPLIADOS
costo_alimentacion = cantidad √ó d√≠as √ó 0-5.0 Bs/d√≠a (60% probabilidad)
# Rango: 0 Bs hasta ~1,800 Bs (100 animales √ó 3 d√≠as √ó 5.0 Bs)

# Costos fijos - RANGOS AMPLIADOS
costo_fijo_total = 100-2,500 Bs (distribuci√≥n normal, media=1000, desv=700)
```

**‚ö†Ô∏è IMPORTANTE: RANGOS DE ENTRENAMIENTO vs VALORES REALES**

Los rangos mostrados son los usados para **generar datos sint√©ticos** durante el entrenamiento. Sin embargo:

1. **El modelo puede manejar valores fuera del rango:**
   - La normalizaci√≥n (StandardScaler) transforma todos los valores a la misma escala
   - La regresi√≥n lineal puede **extrapolar** (predecir fuera del rango visto)
   - Pero la precisi√≥n puede disminuir cuanto m√°s lejos est√© del rango de entrenamiento

2. **Ejemplo pr√°ctico:**
   - Rango entrenamiento (nuevo): log√≠stica 150-6,500 Bs
   - Valor real: 864 Bs (dentro del rango) ‚úÖ
   - Valor real: 5,000 Bs (dentro del nuevo rango) ‚úÖ
   - Valor real: 8,000 Bs (fuera del rango) ‚ö†Ô∏è Funciona, pero menos preciso

3. **Recomendaciones:**
   - ‚úÖ Valores dentro del rango: M√°xima precisi√≥n
   - ‚ö†Ô∏è Valores ligeramente fuera: Funciona bien
   - ‚ùå Valores muy fuera: Considerar re-entrenar el modelo con datos m√°s amplios

#### 2.3. Calcular precio de venta (TARGET)
```python
# 1. Costos adicionales por kg
costo_adicional_por_kg = (log√≠stica + alimentaci√≥n) / kilos_salida

# 2. Costos fijos por kg
costo_fijo_por_kg = costo_fijo_total / kilos_salida

# 3. Margen seg√∫n estacionalidad
if mes in [12, 1]:  # Alta demanda
    margen = 10-20%
elif mes in [5, 6]:  # Baja demanda
    margen = 3-10%
else:
    margen = 5-15%

# 4. Precio final
precio_base = precio_compra + costos_adicionales + costos_fijos
precio_venta_final_kg = precio_base √ó (1 + margen) + ruido_market
```

**Resultado:** DataFrame con 360 filas, cada una con:
- 10 features (inputs)
- 1 target: `precio_venta_final_kg` (output a predecir)

---

## 3. PREPARACI√ìN DE FEATURES

**Archivo:** `api/ml/data/generate_data.py` ‚Üí `construir_features()`

### Las 10 Features del Modelo:

```python
features = {
    1. "cantidad_animales": int,              # Nivel I
    2. "peso_promedio_entrada": float,        # Nivel I
    3. "precio_compra_kg": float,              # Nivel I
    4. "costo_logistica_total": float,         # Nivel II
    5. "costo_alimentacion_estadia": float,   # Nivel II
    6. "duracion_estadia_dias": int,          # Nivel II
    7. "mes_adquisicion": int,                # Nivel II
    8. "costo_total_lote": float,             # Feature Engineering (CTL)
    9. "peso_salida": float,                  # Feature adicional
    10. "costo_fijo_por_kg": float,           # Nivel III
}

# Feature Engineering: CTL (Costo Total por Lote)
costo_total_lote = compra_total + log√≠stica + alimentaci√≥n
```

### ¬øPor qu√© estas features?
- **Nivel I**: Caracter√≠sticas b√°sicas del lote
- **Nivel II**: Costos operativos y contexto temporal
- **Nivel III**: Costos fijos distribuidos
- **CTL**: Feature engineering que concentra el 99.6% de la varianza econ√≥mica

---

## 4. ENTRENAMIENTO DEL MODELO

**Archivo:** `api/ml/core/training_12_months.py`

### 4.1. Divisi√≥n de Datos
```python
X = features (360 √ó 10)  # Matriz de features
y = target (360 √ó 1)      # Vector de precios

# Divisi√≥n 80/20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
# Resultado: 288 lotes para entrenar, 72 para probar
```

### 4.2. Normalizaci√≥n (StandardScaler)
```python
scaler = StandardScaler()
scaler.fit(X_train)  # Aprende media y desviaci√≥n est√°ndar

X_train_scaled = scaler.transform(X_train)  # Normaliza
X_test_scaled = scaler.transform(X_test)

# ¬øPor qu√© normalizar?
# - Diferentes escalas: cantidad_animales (15-100) vs costo_total_lote (30,000+)
# - El modelo necesita valores en la misma escala
# - F√≥rmula: (valor - media) / desviaci√≥n_est√°ndar
```

### 4.3. Comparaci√≥n de Modelos

Se entrenan 3 algoritmos diferentes:

#### A) Linear Regression
```python
model = LinearRegression()
model.fit(X_train_scaled, y_train)
# F√≥rmula aprendida: y = w‚ÇÄ + w‚ÇÅ√óx‚ÇÅ + w‚ÇÇ√óx‚ÇÇ + ... + w‚ÇÅ‚ÇÄ√óx‚ÇÅ‚ÇÄ
# Ventaja: Simple, r√°pido, interpretable
```

#### B) Random Forest Regressor
```python
model = RandomForestRegressor(n_estimators=100, max_depth=10)
model.fit(X_train_scaled, y_train)
# Ventaja: Captura relaciones no lineales, robusto
```

#### C) Gradient Boosting Regressor
```python
model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)
model.fit(X_train_scaled, y_train)
# Ventaja: Secuencial, mejora iterativamente
```

### 4.4. Validaci√≥n Cruzada (K-Fold)

**Archivo:** `api/ml/core/cross_validation.py`

```python
# Divide datos en 5 folds (subconjuntos)
Fold 1: Entrenar en [2,3,4,5], Probar en [1]
Fold 2: Entrenar en [1,3,4,5], Probar en [2]
Fold 3: Entrenar en [1,2,4,5], Probar en [3]
Fold 4: Entrenar en [1,2,3,5], Probar en [4]
Fold 5: Entrenar en [1,2,3,4], Probar en [5]

# Calcula MAE y RMSE en cada fold
# Promedia los resultados ‚Üí m√©trica m√°s confiable
```

**Ventajas:**
- Usa todos los datos para entrenar y probar
- Reduce riesgo de sobreajuste
- M√©tricas m√°s confiables

### 4.5. Selecci√≥n del Mejor Modelo - EXPLICACI√ìN DETALLADA

```python
# Compara m√©tricas de los 3 modelos
mejor_modelo = min(modelos, key=lambda m: m['mae'])

# Criterios:
# 1. Menor MAE (Mean Absolute Error)
# 2. Menor RMSE (Root Mean Squared Error)
# 3. Mayor R¬≤ (coeficiente de determinaci√≥n)
# 4. Validaci√≥n cruzada estable
```

#### ¬øQu√© significan estos criterios?

##### 1. MAE (Mean Absolute Error) - Error Absoluto Medio

**¬øQu√© es?**
El promedio de cu√°nto se equivoca el modelo en sus predicciones.

**F√≥rmula:**
```
MAE = (1/n) √ó Œ£|precio_real - precio_predicho|
```

**Ejemplo pr√°ctico:**
Si predices 3 lotes:
- Lote 1: Real = 25.00, Predicho = 24.50 ‚Üí Error = 0.50
- Lote 2: Real = 23.00, Predicho = 23.80 ‚Üí Error = 0.80
- Lote 3: Real = 26.00, Predicho = 25.30 ‚Üí Error = 0.70
- **MAE = (0.50 + 0.80 + 0.70) / 3 = 0.67 Bs/kg**

**Interpretaci√≥n:**
- MAE = 0.467 Bs/kg significa que, en promedio, el modelo se equivoca por 0.47 Bs/kg
- **Menor es mejor**: Un MAE de 0.3 es mejor que uno de 0.5

**¬øPor qu√© es importante?**
- Te dice directamente cu√°nto error puedes esperar
- F√°cil de interpretar: "El modelo se equivoca en promedio por X Bs/kg"

##### 2. RMSE (Root Mean Squared Error) - Ra√≠z del Error Cuadr√°tico Medio

**¬øQu√© es?**
Similar al MAE, pero penaliza m√°s los errores grandes.

**F√≥rmula:**
```
RMSE = ‚àö[(1/n) √ó Œ£(precio_real - precio_predicho)¬≤]
```

**Ejemplo pr√°ctico:**
Mismos 3 lotes:
- Lote 1: Error = 0.50 ‚Üí Error¬≤ = 0.25
- Lote 2: Error = 0.80 ‚Üí Error¬≤ = 0.64
- Lote 3: Error = 0.70 ‚Üí Error¬≤ = 0.49
- **RMSE = ‚àö[(0.25 + 0.64 + 0.49) / 3] = ‚àö0.46 = 0.68 Bs/kg**

**Diferencia con MAE:**
- Si un error es muy grande (ej: 2.0 Bs/kg), el MAE lo cuenta como 2.0
- El RMSE lo cuenta como 2.0¬≤ = 4.0, penaliz√°ndolo m√°s
- **RMSE siempre ser√° ‚â• MAE**

**Interpretaci√≥n:**
- RMSE = 0.589 Bs/kg significa que los errores grandes son penalizados
- **Menor es mejor**: Un RMSE bajo indica predicciones consistentes

**¬øCu√°ndo usar cada uno?**
- **MAE**: Si todos los errores son igualmente importantes
- **RMSE**: Si quieres evitar errores muy grandes (m√°s conservador)

##### 3. R¬≤ (Coeficiente de Determinaci√≥n) - R-Squared

**¬øQu√© es?**
Mide qu√© porcentaje de la variaci√≥n en los precios es explicado por el modelo.

**F√≥rmula:**
```
R¬≤ = 1 - (SS_res / SS_tot)

Donde:
- SS_res = Suma de errores al cuadrado (residuales)
- SS_tot = Suma de diferencias al cuadrado (total)
```

**Interpretaci√≥n:**
- **R¬≤ = 0.929** significa que el modelo explica el **92.9%** de la variaci√≥n en precios
- Solo el 7.1% de la variaci√≥n no es explicada por el modelo
- **Mayor es mejor**: R¬≤ = 1.0 ser√≠a perfecto (100% explicado)

**Escala de R¬≤:**
- **R¬≤ = 1.0**: Modelo perfecto (imposible en la realidad)
- **R¬≤ = 0.9-1.0**: Excelente (90-100% explicado) ‚úÖ Tu modelo est√° aqu√≠
- **R¬≤ = 0.7-0.9**: Bueno (70-90% explicado)
- **R¬≤ = 0.5-0.7**: Aceptable (50-70% explicado)
- **R¬≤ < 0.5**: Malo (menos del 50% explicado)

**Ejemplo visual:**
```
Si los precios reales var√≠an entre 20-30 Bs/kg:
- R¬≤ = 0.929 ‚Üí El modelo explica el 92.9% de esa variaci√≥n
- El 7.1% restante es "ruido" o factores no capturados
```

##### 4. Validaci√≥n Cruzada Estable

**¬øQu√© significa "estable"?**
Que las m√©tricas no var√≠an mucho entre diferentes folds.

**Ejemplo:**
```
Modelo A (estable):
  Fold 1: MAE = 0.55
  Fold 2: MAE = 0.52
  Fold 3: MAE = 0.54
  Fold 4: MAE = 0.53
  Fold 5: MAE = 0.56
  Promedio: 0.54 ¬± 0.015 (poca variaci√≥n) ‚úÖ

Modelo B (inestable):
  Fold 1: MAE = 0.45
  Fold 2: MAE = 0.65
  Fold 3: MAE = 0.40
  Fold 4: MAE = 0.70
  Fold 5: MAE = 0.50
  Promedio: 0.54 ¬± 0.12 (mucha variaci√≥n) ‚ö†Ô∏è
```

**¬øPor qu√© es importante?**
- Un modelo estable es m√°s confiable
- Si var√≠a mucho entre folds, puede que no generalice bien
- Tu modelo tiene CV MAE = 0.550 ¬± 0.022 ‚Üí **Muy estable** ‚úÖ

#### Criterio de Selecci√≥n Final:

El sistema selecciona el modelo con **menor MAE** porque:
1. Es la m√©trica m√°s f√°cil de interpretar
2. Es la que mejor refleja el error promedio esperado
3. Si hay empate, se considera RMSE y R¬≤

**En tu caso:**
- Linear Regression: MAE = 0.467 Bs/kg ‚úÖ **Ganador**
- Random Forest: MAE = 0.532 Bs/kg
- Gradient Boosting: MAE = 0.545 Bs/kg

**Resultado actual (modelo re-entrenado con rangos ampliados):** Linear Regression gana por:
- MAE: 0.467 Bs/kg (mejorado)
- R¬≤: 0.929 (explica 92.9% de la varianza - excelente)
- CV MAE: 0.550 ¬± 0.022 Bs/kg (validaci√≥n cruzada)
- R√°pido, simple e interpretable

### 4.6. Guardado del Modelo

```python
model_data = {
    'model': mejor_modelo_entrenado,
    'scaler': scaler_fitted,
    'feature_names': ['cantidad_animales', ...],
    'metrics': {...},
    ...
}

joblib.dump(model_data, 'ml/models/12_months_model.pkl')
```

---

## 5. PREDICCI√ìN EN TIEMPO REAL

**Archivo:** `api/routes/v1/prediccion.py` ‚Üí `predict_lote()`

### 5.1. Obtener Datos del Lote
```python
# Desde la base de datos
lote = db.lote.find_unique(id_lote=1400)
costos = db.costo.find_many(id_lote=1400)
produccion = db.produccion.find_unique(id_lote=1400)
```

### 5.2. Construir Features

**Archivo:** `api/services/features_service.py` ‚Üí `build_features_para_modelo()`

```python
# Calcula las 10 features del lote real (ejemplo: lote 1400)
features = {
    "cantidad_animales": 16,
    "peso_promedio_entrada": 98.91,
    "precio_compra_kg": 20.68,
    "costo_logistica_total": 864.00,
    "costo_alimentacion_estadia": 339.75,
    "duracion_estadia_dias": 1,
    "mes_adquisicion": 12,
    "costo_total_lote": 33,936.83,
    "peso_salida": 1,601.01,  # Con ganancia de peso (1.15 kg/d√≠a/cerdo)
    "costo_fijo_por_kg": 0.37,
}
```

### 5.3. Normalizar Features
```python
# Cargar modelo y scaler guardados
model_data = joblib.load('ml/models/12_months_model.pkl')
model = model_data['model']
scaler = model_data['scaler']

# Construir vector de entrada (ejemplo: lote 1400)
X = [[16, 98.91, 20.68, 864, 339.75, 1, 12, 33936.83, 1601.01, 0.37]]

# Normalizar con el mismo scaler usado en entrenamiento
X_scaled = scaler.transform(X)
# Resultado: valores normalizados en la misma escala que el entrenamiento
# Ejemplo: [16, 98.91, ...] ‚Üí [-0.98, 1.2, ...] (valores normalizados)
```

### 5.4. Hacer Predicci√≥n
```python
# El modelo predice directamente el precio
precio_ml_base = model.predict(X_scaled)[0]
# Resultado: 24.79 Bs/kg (ejemplo con lote 1400, modelo re-entrenado)
```

### 5.5. Aplicar Margen Adicional
```python
# Si el usuario selecciona un margen (ej: 10%)
margen_rate = 0.10

# Aplicar margen sobre el precio base
precio_final = precio_ml_base * (1 + margen_rate)
# Resultado: 24.79 √ó 1.10 = 27.27 Bs/kg (ejemplo con lote 1400)
```

### 5.6. Calcular M√©tricas Financieras
```python
ingreso_total = precio_final √ó kilos_salida
costo_total = compra + costos_variables + costos_fijos
ganancia_neta = ingreso_total - costo_total
roi = (ganancia_neta / costo_total) √ó 100
```

---

## 6. COMPONENTES T√âCNICOS

### 6.1. StandardScaler (Normalizaci√≥n) - EXPLICACI√ìN DETALLADA

#### ¬øQu√© es StandardScaler?

**StandardScaler** es una t√©cnica de preprocesamiento que transforma todas las features (variables de entrada) para que tengan la misma escala estad√≠stica.

#### ¬øPor qu√© es necesario?

**Problema sin normalizaci√≥n:**
Imagina que tienes estas features:
- `cantidad_animales`: valores entre 15-100
- `costo_total_lote`: valores entre 20,000-50,000 Bs

Si no normalizas:
- El modelo ver√° que `costo_total_lote` tiene valores mucho m√°s grandes
- Pensar√° que es m√°s importante (aunque no necesariamente lo sea)
- `cantidad_animales` ser√° ignorada porque sus valores son peque√±os

**Soluci√≥n con StandardScaler:**
- Transforma ambas features a la misma escala
- Ambas tienen igual "peso" en el modelo
- El modelo puede aprender correctamente la importancia real de cada feature

#### ¬øQu√© hace exactamente?

**Transformaci√≥n Z-score (estandarizaci√≥n):**

```
valor_normalizado = (valor - media) / desviaci√≥n_est√°ndar
```

**Resultado:**
- **Media = 0**: Los valores se centran en cero
- **Desviaci√≥n est√°ndar = 1**: Todos tienen la misma "dispersi√≥n"

#### Ejemplo Pr√°ctico:

**Feature: cantidad_animales**
```
Valores originales: [15, 20, 25, 30, 50, 80, 100]
Media: 45.7
Desviaci√≥n est√°ndar: 30.2

Valor a normalizar: 16
Normalizado: (16 - 45.7) / 30.2 = -0.98
```

**Feature: costo_total_lote**
```
Valores originales: [20,000, 25,000, 30,000, 35,000, 40,000, 45,000, 50,000]
Media: 35,000
Desviaci√≥n est√°ndar: 10,801

Valor a normalizar: 33,937
Normalizado: (33,937 - 35,000) / 10,801 = -0.10
```

**Resultado:**
- Ambos valores est√°n ahora en la misma escala (-0.98 y -0.10)
- El modelo puede compararlos directamente
- Ninguna feature domina sobre la otra

#### Proceso en tu Sistema:

**1. Durante el Entrenamiento:**
```python
scaler = StandardScaler()
scaler.fit(X_train)  # Aprende media y desv. est√°ndar de cada feature

# Guarda:
# - Media de cada feature
# - Desviaci√≥n est√°ndar de cada feature
```

**2. Durante la Predicci√≥n:**
```python
# Carga el scaler guardado
scaler = model_data['scaler']

# Normaliza las features del lote nuevo
X_scaled = scaler.transform(X_nuevo)

# Usa las mismas medias y desviaciones del entrenamiento
```

**‚ö†Ô∏è IMPORTANTE:**
- Debes usar el **mismo scaler** del entrenamiento
- No puedes crear un scaler nuevo para cada predicci√≥n
- Si cambias el scaler, las predicciones ser√°n incorrectas

#### Ventajas de StandardScaler:

‚úÖ **Igual peso**: Todas las features tienen la misma importancia inicial
‚úÖ **Convergencia r√°pida**: Los algoritmos de ML convergen m√°s r√°pido
‚úÖ **Mejor precisi√≥n**: El modelo puede aprender mejor las relaciones
‚úÖ **Estable**: Funciona bien con la mayor√≠a de algoritmos

#### Alternativas (no usadas en tu sistema):

- **MinMaxScaler**: Escala entre 0 y 1 (no usado aqu√≠)
- **RobustScaler**: Usa mediana en lugar de media (m√°s robusto a outliers)
- **Sin normalizaci√≥n**: Solo funciona si todas las features ya est√°n en la misma escala

#### Ejemplo Visual:

```
ANTES (sin normalizar):
cantidad_animales:    [15, 20, 25, 30, 50, 80, 100]
costo_total_lote:    [20,000, 25,000, 30,000, 35,000, 40,000, 45,000, 50,000]
                      ‚Üë
                      costo_total_lote domina porque es mucho m√°s grande

DESPU√âS (normalizado):
cantidad_animales:    [-1.0, -0.8, -0.7, -0.5, 0.1, 1.1, 1.8]
costo_total_lote:    [-1.4, -0.9, -0.5, 0.0, 0.5, 0.9, 1.4]
                      ‚Üë
                      Ambas en la misma escala, igual peso
```

### 6.2. Linear Regression (Modelo Final) - EXPLICACI√ìN DETALLADA

#### ¬øQu√© es la Regresi√≥n Lineal?

La **Regresi√≥n Lineal** es un algoritmo de Machine Learning que encuentra la mejor l√≠nea recta (o plano en m√∫ltiples dimensiones) que relaciona las caracter√≠sticas de entrada (features) con el valor a predecir (target).

**Analog√≠a simple:**
Imagina que tienes un gr√°fico con puntos dispersos. La regresi√≥n lineal dibuja la l√≠nea recta que mejor se ajusta a esos puntos, minimizando la distancia entre la l√≠nea y todos los puntos.

#### F√≥rmula Matem√°tica:

```
y = w‚ÇÄ + w‚ÇÅ√óx‚ÇÅ + w‚ÇÇ√óx‚ÇÇ + w‚ÇÉ√óx‚ÇÉ + ... + w‚ÇÅ‚ÇÄ√óx‚ÇÅ‚ÇÄ

Donde:
- y = precio_venta_final_kg (lo que queremos predecir)
- w‚ÇÄ = intercepto (t√©rmino constante, el "punto de partida")
- w‚ÇÅ, w‚ÇÇ, ..., w‚ÇÅ‚ÇÄ = coeficientes (pesos aprendidos)
- x‚ÇÅ, x‚ÇÇ, ..., x‚ÇÅ‚ÇÄ = features normalizadas (entradas)
```

#### Ejemplo Pr√°ctico con tu Modelo:

Para el lote 1400, el modelo aprendi√≥ algo como:
```
precio = 15.2 + (0.8 √ó cantidad_animales) + (0.05 √ó peso_entrada) 
        + (0.9 √ó precio_compra) + (0.001 √ó log√≠stica) + ...
```

**Interpretaci√≥n:**
- Si `precio_compra` aumenta 1 Bs/kg ‚Üí el precio predicho aumenta ~0.9 Bs/kg
- Si `cantidad_animales` aumenta 10 ‚Üí el precio predicho aumenta ~8 Bs/kg
- El intercepto (15.2) es el precio base cuando todas las features son 0

#### Proceso de Aprendizaje (Entrenamiento):

1. **Inicializaci√≥n**: El modelo empieza con pesos aleatorios (w‚ÇÄ, w‚ÇÅ, ..., w‚ÇÅ‚ÇÄ)
2. **Predicci√≥n**: Calcula `y_pred = w‚ÇÄ + w‚ÇÅ√óx‚ÇÅ + ... + w‚ÇÅ‚ÇÄ√óx‚ÇÅ‚ÇÄ` para cada lote
3. **Error**: Compara predicci√≥n vs valor real: `error = y_real - y_pred`
4. **Ajuste**: Modifica los pesos para reducir el error
5. **Repetici√≥n**: Repite pasos 2-4 miles de veces hasta minimizar el error

**M√©todo usado:** M√≠nimos Cuadrados (Ordinary Least Squares - OLS)
- Encuentra los pesos que minimizan la suma de errores al cuadrado
- Matem√°ticamente garantiza la mejor soluci√≥n posible

#### Ventajas de Regresi√≥n Lineal:

‚úÖ **Simple y r√°pida**: F√°cil de entender e implementar
‚úÖ **Interpretable**: Puedes ver exactamente c√≥mo cada feature afecta el precio
‚úÖ **Eficiente**: Entrena y predice muy r√°pido
‚úÖ **Estable**: No tiene hiperpar√°metros complejos que ajustar
‚úÖ **Funciona bien**: En muchos casos es tan buena como modelos m√°s complejos

#### Desventajas:

‚ö†Ô∏è **Asume relaci√≥n lineal**: Si la relaci√≥n real es muy compleja/no-lineal, puede no capturarla bien
‚ö†Ô∏è **Sensible a outliers**: Valores extremos pueden afectar mucho el modelo

#### ¬øPor qu√© funciona bien en tu caso?

En tu negocio de reventa de cerdos:
- Las relaciones son principalmente lineales (m√°s costos ‚Üí m√°s precio)
- El precio depende de sumas y proporciones (costos + margen)
- No hay relaciones muy complejas o no-lineales
- Por eso Linear Regression es perfecto para este problema

### 6.3. Validaci√≥n Cruzada (K-Fold)

**Proceso:**
```
Datos: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

Fold 1: Entrenar [2-10], Probar [1] ‚Üí MAE‚ÇÅ
Fold 2: Entrenar [1,3-10], Probar [2] ‚Üí MAE‚ÇÇ
...
Fold 5: Entrenar [1-4,6-10], Probar [5] ‚Üí MAE‚ÇÖ

MAE final = (MAE‚ÇÅ + MAE‚ÇÇ + ... + MAE‚ÇÖ) / 5
```

**Ventajas:**
- Usa todos los datos
- Reduce riesgo de sobreajuste
- M√©tricas m√°s confiables

### 6.4. M√©tricas de Evaluaci√≥n

**MAE (Mean Absolute Error):**
```
MAE = (1/n) √ó Œ£|y_real - y_pred|
```
- Error promedio en Bs/kg
- Ejemplo: MAE = 0.498 ‚Üí error promedio de 0.50 Bs/kg

**RMSE (Root Mean Squared Error):**
```
RMSE = ‚àö[(1/n) √ó Œ£(y_real - y_pred)¬≤]
```
- Penaliza errores grandes m√°s que MAE
- Ejemplo: RMSE = 0.65 Bs/kg

**R¬≤ (Coeficiente de Determinaci√≥n):**
```
R¬≤ = 1 - (SS_res / SS_tot)
```
- Proporci√≥n de varianza explicada
- R¬≤ = 0.752 ‚Üí el modelo explica 75.2% de la variaci√≥n en precios

---

## üéØ RESUMEN EJECUTIVO

### Flujo Completo:

1. **ENTRENAMIENTO (Offline, una vez)**
   - Genera 360 lotes sint√©ticos
   - Entrena 3 modelos con validaci√≥n cruzada
   - Selecciona mejor modelo (Linear Regression)
   - Guarda modelo + scaler

2. **PREDICCI√ìN (Online, cada solicitud)**
   - Obtiene datos del lote desde BD
   - Construye 10 features
   - Normaliza con scaler guardado
   - Predice precio con modelo entrenado
   - Aplica margen adicional si se solicita

### Caracter√≠sticas Clave:

- ‚úÖ **10 Features**: Capturan toda la informaci√≥n relevante
- ‚úÖ **Normalizaci√≥n**: StandardScaler asegura igual peso
- ‚úÖ **Validaci√≥n Cruzada**: M√©tricas confiables
- ‚úÖ **Modelo Simple**: Linear Regression (r√°pido, interpretable)
- ‚úÖ **Precisi√≥n**: MAE = 0.467 Bs/kg, R¬≤ = 0.929 (modelo re-entrenado con rangos ampliados)

---

## üìö REFERENCIAS T√âCNICAS

- **Scikit-learn**: Biblioteca de ML en Python
- **Linear Regression**: Algoritmo de regresi√≥n lineal m√∫ltiple
- **StandardScaler**: Normalizaci√≥n Z-score
- **K-Fold Cross-Validation**: Validaci√≥n cruzada con K=5
- **Joblib**: Serializaci√≥n de modelos Python

---

---

## üìñ GLOSARIO Y CONCEPTOS CLAVE

### Regresi√≥n Lineal - Explicaci√≥n Simple

**¬øQu√© es?**
La regresi√≥n lineal es como encontrar la mejor l√≠nea recta que pasa por un conjunto de puntos. En tu caso, esos "puntos" son los lotes de cerdos con sus caracter√≠sticas y precios reales.

**Analog√≠a del mundo real:**
Imagina que tienes un gr√°fico donde:
- Eje X: cantidad de animales
- Eje Y: precio de venta

La regresi√≥n lineal dibuja la l√≠nea que mejor se ajusta a todos tus datos hist√≥ricos. Luego, cuando tienes un nuevo lote, puedes usar esa l√≠nea para predecir su precio.

**En tu sistema:**
- No es solo una l√≠nea (2D), sino un "plano" en 10 dimensiones (una por cada feature)
- El modelo aprende c√≥mo cada caracter√≠stica (cantidad, peso, costos, etc.) afecta el precio final
- La f√≥rmula aprendida es: `precio = constante + (peso‚ÇÅ √ó feature‚ÇÅ) + (peso‚ÇÇ √ó feature‚ÇÇ) + ...`

**¬øPor qu√© funciona bien?**
En tu negocio, el precio depende principalmente de sumas y proporciones:
- Precio = Compra + Costos + Margen
- Esta es una relaci√≥n principalmente lineal, perfecta para regresi√≥n lineal

---

### Criterios de Selecci√≥n del Modelo - Gu√≠a Completa

Cuando entrenas varios modelos (Linear, Random Forest, Gradient Boosting), necesitas decidir cu√°l es el mejor. Aqu√≠ est√°n los criterios:

#### 1. MAE (Error Absoluto Medio) - El Criterio Principal

**Pregunta que responde:** "¬øCu√°nto se equivoca el modelo en promedio?"

**Ejemplo concreto:**
```
Predicciones del modelo para 5 lotes:
Lote 1: Predijo 24.50, Real fue 25.00 ‚Üí Error: 0.50 Bs/kg
Lote 2: Predijo 23.80, Real fue 23.00 ‚Üí Error: 0.80 Bs/kg
Lote 3: Predijo 25.30, Real fue 26.00 ‚Üí Error: 0.70 Bs/kg
Lote 4: Predijo 22.90, Real fue 22.50 ‚Üí Error: 0.40 Bs/kg
Lote 5: Predijo 24.20, Real fue 24.00 ‚Üí Error: 0.20 Bs/kg

MAE = (0.50 + 0.80 + 0.70 + 0.40 + 0.20) / 5 = 0.52 Bs/kg
```

**Interpretaci√≥n:**
- "El modelo se equivoca en promedio por 0.52 Bs/kg"
- Si vendes 1,000 kg, el error promedio ser√≠a de 520 Bs
- **Menor MAE = Mejor modelo**

**Tu modelo actual:** MAE = 0.467 Bs/kg
- Esto significa que, en promedio, el precio predicho est√° a 0.47 Bs/kg del precio real
- Es un error muy bajo (menos del 2% del precio t√≠pico de ~25 Bs/kg)

#### 2. RMSE (Ra√≠z del Error Cuadr√°tico Medio) - Penaliza Errores Grandes

**Pregunta que responde:** "¬øQu√© tan grandes son los peores errores?"

**Mismo ejemplo:**
```
Mismos 5 lotes:
MAE = 0.52 Bs/kg (promedio simple)
RMSE = ‚àö[(0.50¬≤ + 0.80¬≤ + 0.70¬≤ + 0.40¬≤ + 0.20¬≤) / 5]
     = ‚àö[(0.25 + 0.64 + 0.49 + 0.16 + 0.04) / 5]
     = ‚àö[0.316] = 0.56 Bs/kg
```

**Diferencia clave:**
- Si un error es muy grande (ej: 2.0 Bs/kg), el MAE lo cuenta como 2.0
- El RMSE lo cuenta como 2.0¬≤ = 4.0, penaliz√°ndolo m√°s
- **RMSE siempre ser√° ‚â• MAE**

**Cu√°ndo importa:**
- Si quieres evitar errores muy grandes (m√°s conservador)
- Si un error grande es mucho peor que varios errores peque√±os

**Tu modelo actual:** RMSE = 0.589 Bs/kg
- Indica que los errores grandes son controlados
- La diferencia con MAE (0.467) es peque√±a, lo que significa que no hay errores extremos

#### 3. R¬≤ (Coeficiente de Determinaci√≥n) - Qu√© Tan Bien Explica

**Pregunta que responde:** "¬øQu√© porcentaje de la variaci√≥n en precios explica el modelo?"

**Ejemplo visual:**
```
Imagina que los precios reales var√≠an as√≠:
Lote 1: 20.00 Bs/kg
Lote 2: 22.50 Bs/kg
Lote 3: 25.00 Bs/kg
Lote 4: 27.50 Bs/kg
Lote 5: 30.00 Bs/kg

Variaci√≥n total: 10.00 Bs/kg (de 20 a 30)

Si R¬≤ = 0.929:
- El modelo explica el 92.9% de esa variaci√≥n
- Solo el 7.1% es "ruido" o factores no capturados
```

**Escala de interpretaci√≥n:**
- **R¬≤ = 1.0**: Perfecto (100% explicado) - Imposible en la realidad
- **R¬≤ = 0.9-1.0**: Excelente (90-100%) ‚úÖ **Tu modelo est√° aqu√≠**
- **R¬≤ = 0.7-0.9**: Bueno (70-90%)
- **R¬≤ = 0.5-0.7**: Aceptable (50-70%)
- **R¬≤ < 0.5**: Malo (menos del 50%)

**Tu modelo actual:** R¬≤ = 0.929
- Explica el 92.9% de la variaci√≥n en precios
- Solo el 7.1% no es explicado (factores externos, ruido, etc.)
- **Excelente resultado**

#### 4. Validaci√≥n Cruzada Estable - Confiabilidad

**Pregunta que responde:** "¬øEl modelo es consistente o var√≠a mucho?"

**Ejemplo de modelo estable:**
```
Validaci√≥n cruzada (5 folds):
Fold 1: MAE = 0.55 Bs/kg
Fold 2: MAE = 0.52 Bs/kg
Fold 3: MAE = 0.54 Bs/kg
Fold 4: MAE = 0.53 Bs/kg
Fold 5: MAE = 0.56 Bs/kg

Promedio: 0.54 Bs/kg
Desviaci√≥n est√°ndar: ¬±0.015 Bs/kg (muy peque√±a) ‚úÖ ESTABLE
```

**Ejemplo de modelo inestable:**
```
Validaci√≥n cruzada (5 folds):
Fold 1: MAE = 0.45 Bs/kg
Fold 2: MAE = 0.65 Bs/kg
Fold 3: MAE = 0.40 Bs/kg
Fold 4: MAE = 0.70 Bs/kg
Fold 5: MAE = 0.50 Bs/kg

Promedio: 0.54 Bs/kg
Desviaci√≥n est√°ndar: ¬±0.12 Bs/kg (muy grande) ‚ö†Ô∏è INESTABLE
```

**¬øPor qu√© importa?**
- Un modelo estable es m√°s confiable
- Si var√≠a mucho, puede que no generalice bien a nuevos datos
- Prefieres un modelo que siempre funciona "bien" a uno que a veces funciona "muy bien" y a veces "muy mal"

**Tu modelo actual:** CV MAE = 0.550 ¬± 0.022 Bs/kg
- Desviaci√≥n est√°ndar de solo 0.022 ‚Üí **Muy estable** ‚úÖ
- El modelo es consistente en diferentes subconjuntos de datos

---

### StandardScaler - Normalizaci√≥n Explicada

#### ¬øPor qu√© necesitas normalizar?

**Problema real:**
Tus features tienen escalas muy diferentes:
- `cantidad_animales`: 15-100 (n√∫meros peque√±os)
- `costo_total_lote`: 20,000-50,000 (n√∫meros muy grandes)

Sin normalizar, el modelo pensar√≠a:
- "costo_total_lote es m√°s importante porque sus n√∫meros son m√°s grandes"
- Esto es incorrecto: ambas features pueden ser igualmente importantes

**Soluci√≥n: StandardScaler**
Transforma todas las features a la misma escala, d√°ndoles igual "peso" inicial.

#### ¬øC√≥mo funciona?

**F√≥rmula:**
```
valor_normalizado = (valor - media) / desviaci√≥n_est√°ndar
```

**Ejemplo paso a paso:**

**Feature: cantidad_animales**
```
Valores originales: [15, 20, 25, 30, 50, 80, 100]
Media: 45.7
Desviaci√≥n est√°ndar: 30.2

Para normalizar el valor 16:
Normalizado = (16 - 45.7) / 30.2 = -0.98
```

**Feature: costo_total_lote**
```
Valores originales: [20,000, 25,000, 30,000, 35,000, 40,000, 45,000, 50,000]
Media: 35,000
Desviaci√≥n est√°ndar: 10,801

Para normalizar el valor 33,937:
Normalizado = (33,937 - 35,000) / 10,801 = -0.10
```

**Resultado:**
- Ambos valores est√°n ahora en la misma escala (-0.98 y -0.10)
- El modelo puede compararlos directamente
- Ninguna feature domina sobre la otra

#### Proceso en tu Sistema:

**1. Durante el Entrenamiento:**
```python
# El scaler "aprende" las caracter√≠sticas de los datos
scaler = StandardScaler()
scaler.fit(X_train)

# Guarda internamente:
# - Media de cada feature: [45.7, 35,000, ...]
# - Desviaci√≥n est√°ndar de cada feature: [30.2, 10,801, ...]
```

**2. Durante la Predicci√≥n:**
```python
# Carga el scaler guardado (con las medias y desviaciones aprendidas)
scaler = model_data['scaler']

# Normaliza las features del lote nuevo usando las mismas estad√≠sticas
X_scaled = scaler.transform(X_nuevo)

# Usa las mismas medias y desviaciones del entrenamiento
# Esto es CR√çTICO: debe usar los mismos par√°metros
```

**‚ö†Ô∏è IMPORTANTE:**
- Debes usar el **mismo scaler** del entrenamiento
- No puedes crear un scaler nuevo para cada predicci√≥n
- Si cambias el scaler, las predicciones ser√°n incorrectas
- Es como usar una regla diferente para medir: los resultados no ser√≠an comparables

#### Ventajas:

‚úÖ **Igual peso**: Todas las features tienen la misma importancia inicial
‚úÖ **Convergencia r√°pida**: Los algoritmos de ML convergen m√°s r√°pido
‚úÖ **Mejor precisi√≥n**: El modelo puede aprender mejor las relaciones
‚úÖ **Estable**: Funciona bien con la mayor√≠a de algoritmos

#### Ejemplo Visual:

```
ANTES (sin normalizar):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cantidad_animales:    [15, 20, 25]  ‚îÇ ‚Üê N√∫meros peque√±os
‚îÇ costo_total_lote:     [20k, 25k, 30k] ‚îÇ ‚Üê N√∫meros muy grandes
‚îÇ                                      ‚îÇ
‚îÇ El modelo piensa:                    ‚îÇ
‚îÇ "costo_total_lote es m√°s importante" ‚îÇ ‚ùå Incorrecto
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

DESPU√âS (normalizado):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ cantidad_animales:    [-1.0, -0.8, -0.7] ‚îÇ ‚Üê Misma escala
‚îÇ costo_total_lote:     [-1.4, -0.9, -0.5] ‚îÇ ‚Üê Misma escala
‚îÇ                                      ‚îÇ
‚îÇ El modelo piensa:                    ‚îÇ
‚îÇ "Ambas tienen igual peso inicial"    ‚îÇ ‚úÖ Correcto
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

**√öltima actualizaci√≥n:** Diciembre 2024 (Modelo re-entrenado con rangos ampliados)

